{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea1925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Burada kullanacağımız modeli seçiyoruz.\n",
    "model= YOLO(\"yolov8l.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2a85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri dahil ediyoruz. \n",
    "import cv2\n",
    "import numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9fbf7",
   "metadata": {},
   "source": [
    "Koda geçmeden önce buradaki mantığı anlatmak istiyorum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53749f31",
   "metadata": {},
   "source": [
    "Buradaki iki farklı model ile bir videodaki kişilerin konumu, telefonların konumu ve  kişilerin ellerinin konumu tespit ediliyor. Ardından kişinin elindeki spesifik noktalar kullanılarak herhangi bir telefon ile kesişim içinde olup olmadığı tespit ediliyor. Eğer bir kesişim varsa bu kişinin hangi kişi olduğunu bulmak için el ile kesişen telefonun kişilerle kesişimine bakılıyor. Buna göre hangi kişide kesişim varsa o kişi telefon ile uğraşıyor diyoruz.\n",
    "\n",
    "Bu yöntemin her zaman olmasa da iki tane ufak sorunu var. Birincisi bazen kamera açısından dolayı telefon uğtaşan kişinin elinet gözükmüyor. Diğeri ise bazen kişiler birbirine çok yakın ise bulduğumuz kesişim noktası başka bir kişi ile daha kesişebiliyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3fea3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kamera= cv2.VideoCapture('video1.mp4')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# El tespitinde kullanacağımız modeli tanımlıyoruz\n",
    "detector=HandDetector(maxHands=5)\n",
    "\n",
    "while True:\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    ret,kare=kamera.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # videoda bulunan insanların konumunu tutan liste\n",
    "    person_list=[]\n",
    "    \n",
    "    # videoda bulunan telefonların  konumunu tutan liste\n",
    "    phone_list=[]\n",
    "    \n",
    "    # Resmi RGB formata çevirip nesne nesne tespit modeline veriyoruz.\n",
    "    imgs=cv2.cvtColor(kare,cv2.COLOR_BGR2RGB)\n",
    "    results = model(imgs,verbose=False) \n",
    "    labels=results[0].names\n",
    "    \n",
    "    \n",
    "    for i in range(len(results[0].boxes)):\n",
    "        x1,y1,x2,y2=results[0].boxes.xyxy[i]\n",
    "        score=results[0].boxes.conf[i]\n",
    "        label=results[0].boxes.cls[i]\n",
    "        x1,y1,x2,y2,score,label=int(x1),int(y1),int(x2),int(y2),float(score),int(label)\n",
    "        name=labels[label]\n",
    "        \n",
    "        # %50'nin altında bulunan nesneleri göz ardı ediyoruz.\n",
    "        if score<0.5:\n",
    "            continue\n",
    "        # Eğer nesne insan ise bu nesnenin konumunu gerekli listenin içine ekliyoruz.\n",
    "        if name=='person':\n",
    "            \n",
    "            person_list.append((x1,y1,x2,y2))\n",
    "            \n",
    "        # Aynısını telefon için yapıyoruz.\n",
    "        if name=='cell phone':\n",
    "            \n",
    "            phone_list.append((x1,y1,x2,y2))  \n",
    "          \n",
    "            \n",
    "\n",
    "    # Burada videodaki karenin kopyası oluşturuluyor.\n",
    "    # Bunun sebebi el tespitinde yapılan işlemler orijinal görseli etkilemesin diye\n",
    "    copy=kare.copy() \n",
    "    \n",
    "    # Burada kopya görseli el tespit modeline veriyoruz.\n",
    "    hands,copy=detector.findHands(copy,flipType=False)\n",
    "    \n",
    "    # Resimdeki el ile kesişen telefonların orta noktaların konumunu bununla tutuyoruz\n",
    "    hand_list=[]\n",
    "    \n",
    "    # Burada her bir telefon için resimde bir bölge oluşturacağız.\n",
    "    for phone in phone_list:\n",
    "        (x21,y21,x22,y22)=phone\n",
    "        region1=np.array([(x21,y21),(x22,y21),(x22,y22),(x21,y22)])\n",
    "            \n",
    "        region1 = region1.reshape((-1,1,2))\n",
    "        \n",
    "        # Burada her bir el için eldeki tüm noktalara bakacağız.\n",
    "        for hand in hands:\n",
    "            # 21 deme sebebimiz elde 21 adet nokta bulunması\n",
    "            for j in range(21):\n",
    "                # Her bir konumu sırayla alıyoruz.\n",
    "                x,y,z=hand['lmList'][j]\n",
    "                # Her bir nokta için bu noktanın telefonun olduğu bölgenin içinde olup olmadığına bakıyoruz.\n",
    "                inside_region1=cv2.pointPolygonTest(region1,(x,y),False)\n",
    "                # Eğer elin bir noktası telefonun olduğu bölgenin içinde ise o telefonun orta noktasını uygun listeye ekliyoruz \n",
    "                if inside_region1>0:\n",
    "                    cx=int(x21/2+x22/2)\n",
    "                    cy=int(y21/2+y22/2)\n",
    "                    hand_list.append((cx,cy))\n",
    "                    \n",
    "    # Burada ise her görseldeki her bir kişi için bir bölge oluşturup \n",
    "    # el ile kesişen telefonun orta noktası var mı diye bakıyoruz. \n",
    "    # Eğer var ise control değişkenini true yapıyoruz.\n",
    "    for person in person_list:\n",
    "        control=False\n",
    "        (x21,y21,x22,y22)=person\n",
    "        region1=np.array([(x21,y21),(x22,y21),(x22,y22),(x21,y22)])\n",
    "            \n",
    "        region1 = region1.reshape((-1,1,2))\n",
    "        \n",
    "        for hand in hand_list:\n",
    "                (x,y)=hand\n",
    "                inside_region1=cv2.pointPolygonTest(region1,(x,y),False)\n",
    "                if inside_region1>0:\n",
    "                    control=True\n",
    "                   \n",
    "        # Eğer bu kişi telefon ile uğraşıyorsa kare içine alınıp aşağıdaki yazı yazılıyor.\n",
    "        if control:\n",
    "            cv2.rectangle(kare,(x21,y21),(x22,y22),(102,0,153),5)\n",
    "            cv2.putText(kare, 'Phone Detected',(x21, y21-20), font, 2, (255,0,0), 2)\n",
    "            \n",
    "            \n",
    "                    \n",
    "            \n",
    "         \n",
    "\n",
    "        \n",
    "    \n",
    "    cv2.imshow(\"kamera\",kare)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "kamera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
